{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# url, date, title 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naver_crawling(result, naver_url):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"headless\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\", chrome_options=options)\n",
    "    driver.get(naver_url)\n",
    "\n",
    "    prev_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    # 웹페이지 맨 아래까지 무한 스크롤\n",
    "    while True:        \n",
    "        driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "        time.sleep(2)\n",
    "        curr_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        if(curr_height == prev_height):\n",
    "            break\n",
    "        else:\n",
    "            prev_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    # url, date, title\n",
    "    contents = driver.find_elements_by_css_selector('div.total_area')\n",
    "\n",
    "    for content in contents:\n",
    "        url = content.find_element_by_css_selector('a.api_txt_lines.total_tit').get_attribute('href')\n",
    "        date = content.find_element_by_css_selector('span.sub_time.sub_txt').text\n",
    "        title = content.find_element_by_css_selector('a.api_txt_lines.total_tit').text\n",
    "\n",
    "        result.append([url, date, title])\n",
    "        \n",
    "    driver.quit()\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-e3966ea796fe>:6: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(\"chromedriver.exe\", chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "# url, date, title 정보\n",
    "result = []\n",
    "\n",
    "# 20200201 ~ 20200930\n",
    "keyword = \"한달살기\"\n",
    "naver_url = \"https://search.naver.com/search.naver?where=blog&query=\"+ quote(keyword) + \"&sm=tab_opt&nso=so%3Ar%2Cp%3Afrom20200201to20200930\"\n",
    "result = naver_crawling(result, naver_url)\n",
    "\n",
    "# 20201001 ~ 20210531\n",
    "naver_url = \"https://search.naver.com/search.naver?where=blog&query=\"+ quote(keyword) + \"&sm=tab_opt&nso=so%3Ar%2Cp%3Afrom20201001to20210531\"\n",
    "result = naver_crawling(result, naver_url)\n",
    "\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "naver_df = pd.DataFrame(result)\n",
    "naver_df.columns = ['url', 'date', 'title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hashtag, 글내용 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-666ce259e167>:8: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(\"chromedriver.exe\", chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20번째\n",
      "40번째\n",
      "60번째\n",
      "80번째\n",
      "100번째\n",
      "120번째\n",
      "140번째\n",
      "160번째\n",
      "180번째\n",
      "200번째\n",
      "220번째\n",
      "240번째\n",
      "260번째\n",
      "280번째\n",
      "300번째\n",
      "320번째\n",
      "340번째\n",
      "360번째\n",
      "380번째\n",
      "400번째\n",
      "420번째\n",
      "440번째\n",
      "460번째\n",
      "480번째\n",
      "500번째\n",
      "에러방지용 sleep 진행중\n",
      "520번째\n",
      "540번째\n",
      "560번째\n",
      "580번째\n",
      "600번째\n",
      "620번째\n",
      "640번째\n",
      "660번째\n",
      "680번째\n",
      "700번째\n",
      "720번째\n",
      "740번째\n",
      "760번째\n",
      "780번째\n",
      "800번째\n",
      "820번째\n",
      "840번째\n",
      "860번째\n",
      "880번째\n",
      "900번째\n",
      "920번째\n",
      "940번째\n",
      "960번째\n",
      "980번째\n",
      "1000번째\n",
      "에러방지용 sleep 진행중\n",
      "1020번째\n",
      "1040번째\n",
      "1060번째\n",
      "1080번째\n",
      "1100번째\n",
      "1120번째\n",
      "1140번째\n",
      "1160번째\n",
      "1180번째\n",
      "1200번째\n",
      "1220번째\n",
      "1240번째\n",
      "1260번째\n",
      "1280번째\n",
      "1300번째\n",
      "1320번째\n",
      "1340번째\n",
      "1360번째\n",
      "1380번째\n",
      "1400번째\n",
      "1420번째\n",
      "1440번째\n",
      "1460번째\n",
      "1480번째\n",
      "1500번째\n",
      "에러방지용 sleep 진행중\n",
      "1520번째\n",
      "1540번째\n",
      "1560번째\n",
      "1580번째\n",
      "1600번째\n",
      "1620번째\n",
      "1640번째\n",
      "1660번째\n",
      "1680번째\n",
      "1700번째\n",
      "1720번째\n",
      "1740번째\n",
      "1760번째\n",
      "1780번째\n",
      "1800번째\n",
      "1820번째\n",
      "1840번째\n",
      "1860번째\n",
      "1880번째\n",
      "1900번째\n",
      "1920번째\n",
      "1940번째\n",
      "1960번째\n",
      "1980번째\n",
      "2000번째\n",
      "에러방지용 sleep 진행중\n"
     ]
    }
   ],
   "source": [
    "hashtags = []\n",
    "contents = []\n",
    "i = 0\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"headless\")\n",
    "    \n",
    "driver = webdriver.Chrome(\"chromedriver.exe\", chrome_options=options)\n",
    "\n",
    "for blog_url in naver_df['url']:\n",
    "    hashtag_list = []\n",
    "    content_list = []\n",
    "    \n",
    "    # 몇번째인지 확인하는 코드, 추후 삭제 예정\n",
    "    i += 1\n",
    "    if i % 20 == 0:\n",
    "        print(str(i) + \"번째\")\n",
    "    \n",
    "    driver.get(blog_url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # 해시태그 크롤링\n",
    "    try:\n",
    "        driver.switch_to.frame(\"mainFrame\")\n",
    "        page = driver.page_source\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "    except:\n",
    "        page = driver.page_source\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "    \n",
    "    try:\n",
    "        hashtag_data = soup.select(\"a.item.pcol2.itemTagfont._setTop\")\n",
    "    \n",
    "        for hashtag in hashtag_data:\n",
    "            hashtag_list.append(hashtag.text)\n",
    "    \n",
    "    except:\n",
    "        hashtag_list.append(\"에러\")\n",
    "\n",
    "    hashtags.append(hashtag_list)\n",
    "    \n",
    "    # 내용 크롤링\n",
    "    try:\n",
    "        content_data = soup.select(\"div.se-component.se-text.se-l-default\")\n",
    "\n",
    "        for content in content_data:\n",
    "            content_list.append(content.text)\n",
    "        \n",
    "        if len(content_list) == 0:\n",
    "            content_data = soup.select(\"div.post-view p\")\n",
    "            \n",
    "            for content in content_data:\n",
    "                content_list.append(content.text)\n",
    "        \n",
    "        if len(content_list) == 0:\n",
    "            content_data = soup.select(\"div.se_component_wrap.sect_dsc.__se_component_area p\")\n",
    "            \n",
    "            for content in content_data:\n",
    "                content_list.append(content.text)\n",
    "                \n",
    "        if len(content_list) == 0:\n",
    "            content_data = soup.select(\"div.post-view div\")\n",
    "\n",
    "            for content in content_data:\n",
    "                content_list.append(content.text)\n",
    "        \n",
    "    except:\n",
    "        content_list.append(\"에러\")\n",
    "        \n",
    "    contents.append(content_list)\n",
    "    \n",
    "    # 추후 삭제 예정\n",
    "    if i % 500 == 0:\n",
    "        print(\"에러방지용 sleep 진행중\")\n",
    "        time.sleep(180)\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "naver_df['hashtags'] = hashtags\n",
    "naver_df['contents'] = contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 엑셀 파일로 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "naver_df.to_excel(keyword + '.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://blog.naver.com/utiful_sun92?Redirect=L...</td>\n",
       "      <td>2020.09.15.</td>\n",
       "      <td>[제주 한달살기_기록] ep1.19박20일 제주살이 조천리야 반가워!</td>\n",
       "      <td>[#씨앤하우스, #조천카페, #틈, #제주한달살기, #제주도여행, #제주도]</td>\n",
       "      <td>[\\n\\n\\n\\n​\\n\\n\\n\\n, \\n\\n\\n\\n​미래의 나 보라고 이렇게 잘 쉬...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://blog.naver.com/obh1680?Redirect=Log&amp;lo...</td>\n",
       "      <td>2020.09.07.</td>\n",
       "      <td>오션뷰의 제주 한달살기 숙소</td>\n",
       "      <td>[#제주한달살기숙소, #탄탈루스]</td>\n",
       "      <td>[\\n\\n\\n\\n​\\n\\n\\n\\n, \\n\\n\\n\\n​\\n\\n\\n\\n, \\n\\n\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://blog.naver.com/misoagnes?Redirect=Log&amp;...</td>\n",
       "      <td>2020.07.30.</td>\n",
       "      <td>제주 한달 살기 차귀도 배낚시, 협재 해수욕장 모래놀이_4</td>\n",
       "      <td>[#제주도한달살기, #제주한달살기, #차귀도배낚시, #수용횟집배낚시, #수용배낚시,...</td>\n",
       "      <td>[\\n\\n\\n\\n​​​​​​제주도 한달살기 4일째!날씨가 좋지 않았지만 낚시를 하고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://blog.naver.com/mouche007?Redirect=Log&amp;...</td>\n",
       "      <td>2020.02.13.</td>\n",
       "      <td>코타키나발루 숙소 한달살기 가성비 추천</td>\n",
       "      <td>[#코타키나발루숙소, #코타키나발루한달살기, #코타스윗]</td>\n",
       "      <td>[\\n\\n\\n\\n​​​​사원 모두가 블루와 그린으로 이루어졌다는 블루모스크가 창밖으...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://blog.naver.com/youriful?Redirect=Log&amp;l...</td>\n",
       "      <td>2020.02.26.</td>\n",
       "      <td>발리한달살기 #21. 우붓 요가반 수업 후기</td>\n",
       "      <td>[#발리한달살기, #발리우붓요가, #우붓요가반]</td>\n",
       "      <td>[\\n\\n\\n\\nDay 1620190628-0726 발리 한달살기 이야기 \\n\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>https://blog.naver.com/shtaak?Redirect=Log&amp;log...</td>\n",
       "      <td>2021.04.24.</td>\n",
       "      <td>한달살기 전문숙소인 블루하우스 방역하기</td>\n",
       "      <td>[#바닷가바로앞, #블루하우스, #동상일몽, #한달살기, #방역, #살충, #사회적...</td>\n",
       "      <td>[최근 바닷가바로앞 블루하우스인 동상일몽으로 , 한달살기 하러 오시는 분들 중에 ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>https://blog.naver.com/jeju_lotte?Redirect=Log...</td>\n",
       "      <td>2021.05.04.</td>\n",
       "      <td>제주도 호텔, 제주도 한 달 살기 숙소 추천! 롯데호텔 제주, 제주...</td>\n",
       "      <td>[#제주도, #제주, #롯데호텔제주, #롯데호텔, #국내여행지추천, #국내여행, #...</td>\n",
       "      <td>[\\n\\n\\n\\n 일상생활 중 혹은제주 여행을 하면서 문득, ‘제주에 살아보고 싶다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>https://blog.naver.com/j_yun93?Redirect=Log&amp;lo...</td>\n",
       "      <td>2020.12.27.</td>\n",
       "      <td>윤쿠잉 제주 한달살기 : 14일차, 서쪽 여행 끝, 협재해수욕장...</td>\n",
       "      <td>[#윤쿠잉제주라이프, #제주도한달살기]</td>\n",
       "      <td>[\\n\\n\\n\\n윤쿠잉 제주 한달살기 : 14일차, 서쪽 여행 끝, 협재해수욕장, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>https://blog.naver.com/manim159?Redirect=Log&amp;l...</td>\n",
       "      <td>2021.02.10.</td>\n",
       "      <td>(남해한달살기)(남해보름살기)(남해일주일살기)</td>\n",
       "      <td>[#남해날마다소풍, #남해한달살기, #남해보름살기, #남해일주일살기, #경남한달살기...</td>\n",
       "      <td>[#남해한달살기  #남해보름살기  #남해일주일살기, ​, 프라이빗 바다가 펼처진 아...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>https://blog.naver.com/pc_happy700?Redirect=Lo...</td>\n",
       "      <td>2021.04.22.</td>\n",
       "      <td>강원도 한 달 살기_평창군 참여자 모집 안내</td>\n",
       "      <td>[#강원도, #한달살기, #평창군, #참여자, #모집, #안내]</td>\n",
       "      <td>[\\n\\n\\n\\n안녕하세요 여러분~~!!​평창군으로 귀농귀촌을 하고자 하는 예비귀농...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url         date  \\\n",
       "0     https://blog.naver.com/utiful_sun92?Redirect=L...  2020.09.15.   \n",
       "1     https://blog.naver.com/obh1680?Redirect=Log&lo...  2020.09.07.   \n",
       "2     https://blog.naver.com/misoagnes?Redirect=Log&...  2020.07.30.   \n",
       "3     https://blog.naver.com/mouche007?Redirect=Log&...  2020.02.13.   \n",
       "4     https://blog.naver.com/youriful?Redirect=Log&l...  2020.02.26.   \n",
       "...                                                 ...          ...   \n",
       "1995  https://blog.naver.com/shtaak?Redirect=Log&log...  2021.04.24.   \n",
       "1996  https://blog.naver.com/jeju_lotte?Redirect=Log...  2021.05.04.   \n",
       "1997  https://blog.naver.com/j_yun93?Redirect=Log&lo...  2020.12.27.   \n",
       "1998  https://blog.naver.com/manim159?Redirect=Log&l...  2021.02.10.   \n",
       "1999  https://blog.naver.com/pc_happy700?Redirect=Lo...  2021.04.22.   \n",
       "\n",
       "                                         title  \\\n",
       "0       [제주 한달살기_기록] ep1.19박20일 제주살이 조천리야 반가워!   \n",
       "1                              오션뷰의 제주 한달살기 숙소   \n",
       "2             제주 한달 살기 차귀도 배낚시, 협재 해수욕장 모래놀이_4   \n",
       "3                        코타키나발루 숙소 한달살기 가성비 추천   \n",
       "4                     발리한달살기 #21. 우붓 요가반 수업 후기   \n",
       "...                                        ...   \n",
       "1995                     한달살기 전문숙소인 블루하우스 방역하기   \n",
       "1996  제주도 호텔, 제주도 한 달 살기 숙소 추천! 롯데호텔 제주, 제주...   \n",
       "1997    윤쿠잉 제주 한달살기 : 14일차, 서쪽 여행 끝, 협재해수욕장...   \n",
       "1998                 (남해한달살기)(남해보름살기)(남해일주일살기)   \n",
       "1999                  강원도 한 달 살기_평창군 참여자 모집 안내   \n",
       "\n",
       "                                               hashtags  \\\n",
       "0            [#씨앤하우스, #조천카페, #틈, #제주한달살기, #제주도여행, #제주도]   \n",
       "1                                    [#제주한달살기숙소, #탄탈루스]   \n",
       "2     [#제주도한달살기, #제주한달살기, #차귀도배낚시, #수용횟집배낚시, #수용배낚시,...   \n",
       "3                       [#코타키나발루숙소, #코타키나발루한달살기, #코타스윗]   \n",
       "4                            [#발리한달살기, #발리우붓요가, #우붓요가반]   \n",
       "...                                                 ...   \n",
       "1995  [#바닷가바로앞, #블루하우스, #동상일몽, #한달살기, #방역, #살충, #사회적...   \n",
       "1996  [#제주도, #제주, #롯데호텔제주, #롯데호텔, #국내여행지추천, #국내여행, #...   \n",
       "1997                              [#윤쿠잉제주라이프, #제주도한달살기]   \n",
       "1998  [#남해날마다소풍, #남해한달살기, #남해보름살기, #남해일주일살기, #경남한달살기...   \n",
       "1999                [#강원도, #한달살기, #평창군, #참여자, #모집, #안내]   \n",
       "\n",
       "                                               contents  \n",
       "0     [\\n\\n\\n\\n​\\n\\n\\n\\n, \\n\\n\\n\\n​미래의 나 보라고 이렇게 잘 쉬...  \n",
       "1     [\\n\\n\\n\\n​\\n\\n\\n\\n, \\n\\n\\n\\n​\\n\\n\\n\\n, \\n\\n\\n\\...  \n",
       "2     [\\n\\n\\n\\n​​​​​​제주도 한달살기 4일째!날씨가 좋지 않았지만 낚시를 하고...  \n",
       "3     [\\n\\n\\n\\n​​​​사원 모두가 블루와 그린으로 이루어졌다는 블루모스크가 창밖으...  \n",
       "4     [\\n\\n\\n\\nDay 1620190628-0726 발리 한달살기 이야기 \\n\\n\\...  \n",
       "...                                                 ...  \n",
       "1995  [최근 바닷가바로앞 블루하우스인 동상일몽으로 , 한달살기 하러 오시는 분들 중에 ,...  \n",
       "1996  [\\n\\n\\n\\n 일상생활 중 혹은제주 여행을 하면서 문득, ‘제주에 살아보고 싶다...  \n",
       "1997  [\\n\\n\\n\\n윤쿠잉 제주 한달살기 : 14일차, 서쪽 여행 끝, 협재해수욕장, ...  \n",
       "1998  [#남해한달살기  #남해보름살기  #남해일주일살기, ​, 프라이빗 바다가 펼처진 아...  \n",
       "1999  [\\n\\n\\n\\n안녕하세요 여러분~~!!​평창군으로 귀농귀촌을 하고자 하는 예비귀농...  \n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naver_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
